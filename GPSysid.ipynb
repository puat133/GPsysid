{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GP based system identification of reactor dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will go through the GP-system identification model for reactor dynamics. \n",
    "The core of the GP-bases system idenfitication is the assumption that the dynamics is following the state space model as below\n",
    "$$\n",
    "x_{t+1} = f(x_t,u_t) + v_t,\\\\\n",
    "y_t = g(x_t,u_t) + w_t\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ideally, the measurement equation $g(x_t,u_t)$ that relates between the \"latent\" states and the observation should be known. \n",
    "- However, for the reactor dynamics, it is not possible to come up with such an equation.\n",
    "- Therefore, we model both $f$ and $g$ as GP's.\n",
    "- The GP enters the *SSM* by assuming that\n",
    "$$\n",
    "f(x_t,u_t) \\sim {GP} (m_f(x_t,u_t),k_f(x_t,u_t,x_t',u_t')),\\\\\n",
    "g(x_t,u_t) \\sim {GP} (m_g(x_t,u_t),k_g(x_t,u_t,x_t',u_t')),\\\\\n",
    "x_0 \\sim p(x_0), \\\\\n",
    "f_t := f(x_{t-1}),\\\\\n",
    "x_t|f(x_{t-1}) \\sim  \\mathcal{N}(0,Q),\\\\\n",
    "g_t := g(x_t),\\\\\n",
    "y_t|g_t \\sim \\mathcal{N}(0,R).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There could be many ways to build the GP based inference as above.\n",
    "- One idea, is to lump the dynamics of the observation as a state as given in this [reference](https://www.repository.cam.ac.uk/handle/1810/299413).\n",
    "- That is now, we only have GP for the transition function $f$, where the new latent state $z$ are the original latent states and the observations\n",
    "- The observations are some of the last elements in $z_t$\n",
    "$$\n",
    "f(z_t,u_t) \\sim {GP} (m_f(z_t,u_t),k_f(z_t,u_t,z_t',u_t')),\\\\\n",
    "z_0 \\sim p(x_0), \\\\\n",
    "f_t := f(z_{t-1}),\\\\\n",
    "z_t|f(z_{t-1}) \\sim  \\mathcal{N}(0,Q),\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, we can use $m_f$ as a linear dynamics with the structure\n",
    " $$\n",
    " m_f(z_t,u_t) = A_0 z_t + B_0 u_t.\n",
    " $$\n",
    " - The matrices $A$ and $B$ are obtained from linear system identification procedure\n",
    " - Using finite dimensional approximation of the GP of $f$, we write\n",
    " $$\n",
    " f \\sim A_0 z_t + B_0 u_t + A \\Phi(z_t, u_t)\n",
    " $$\n",
    " - Here, $\\Phi$ is a basis function, with the dimension is $n_z \\times n_b^{n_z+n_u}$.  \n",
    " - The matrix $A$ to be sampled by some MCMC, also the covariance matrix $Q$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the algorithm is a typical **MCMC** algorithm that needs quite a long time to run, the GP-sysid is written so that it can run in a cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We implement this in `chemReactor.py`, where all necessary computations are given in `a.py` and `util.py'.\n",
    "- We will use `Numba` to excel the speed and  `SIPPY` which is linear system identification toolbox which can be downloaded from [here](https://github.com/CPCLAB-UNIPI/SIPPY). `Numba` should be installabe from `conda`. \n",
    "- To be able to run the code, `Numba` version should be later than `0.47`.\n",
    "- Now we will some important sections in these python files.\n",
    "- Fist is the core function in `chemReactor.py`\n",
    "```python\n",
    "def chemReactorGP(path,randSeed=0,resampling=5,ma_smoother=14,\n",
    "                    data_extension_percentage=50,\n",
    "                    minSS_orders=5,maxSS_orders=8,useLinear=True,\n",
    "                    samples_num=1000,particles_num=30,\n",
    "                    bases_num=4,ratio_L=1,Kn=10,\n",
    "                    burnPercentage=25,lQ=100,ell=1.,Vgain=1e3):\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Inside this function come some basic things like :\n",
    "  - loading the data\n",
    "     ```python\n",
    "        data = sio.loadmat('ForIdentification.mat')\n",
    "        u = data['u'].T#[::resampling,[-2,-1]];u = u.T#u=u[np.newaxis,:]\n",
    "        y = data['y'].T#[::resampling,:3];y = y.T#y=y[np.newaxis,:]\n",
    "        yVal = data['yVal'].T\n",
    "     ```\n",
    "  - Here `u` is the aromatics and sulfur inlet, and `y` are the $\\Delta T$s\n",
    "  - We only select three $\\Delta T$\n",
    "      ```python\n",
    "        #select only first three\n",
    "        y = y[:3,:]\n",
    "        yVal = yVal[:3,:]\n",
    "        #%%\n",
    "        y = y-y[:,-1][:,np.newaxis]\n",
    "        y = y/(np.max(y)-np.min(y)) #scaled to 0-1\n",
    "        yVal = y/(np.max(yVal)-np.min(yVal)) #scaled to 0-1\n",
    "        u = u - np.mean(u,axis=1)[:,np.newaxis]\n",
    "        #%%\n",
    "      ```\n",
    "  - Next we extend both `u`, `y`, and `yVal`, to match with the basis function condition\n",
    "      ```python\n",
    "        extension = data_extension_percentage # 50% extension\n",
    "        y_extend = np.zeros((y.shape[0],(y.shape[1]*(100+extension)//100)))\n",
    "        yVal_extend = np.zeros((y.shape[0],(yVal.shape[1]*(100+extension)//100)))\n",
    "        u_extend = np.zeros((u.shape[0],(u.shape[1]*(100+extension)//100)))\n",
    "        shift = extension*y.shape[1]//200\n",
    "        y_extend[:,shift:-shift] = y\n",
    "        yVal_extend[:,shift:-shift] = yVal\n",
    "        u_extend[:,shift:-shift] = u\n",
    "      ```\n",
    "  - Next we first run the linear system identification\n",
    "       ```python\n",
    "        #%%\n",
    "        sys_id = sippy.system_identification(y.T,u.T,'N4SID'\n",
    "                                            #  ,centering='InitVal'\n",
    "                                            #  ,SS_p=horizon,SS_f=horizon\n",
    "                                            ,SS_A_stability=True\n",
    "                                            ,IC='AIC'\n",
    "                                            ,SS_orders=[minSS_orders,maxSS_orders]\n",
    "                                            )\n",
    "\n",
    "        #%%\n",
    "        nx = sys_id.A.shape[0]\n",
    "        iA = sys_id.A #np.random.randn(nx,nx)\n",
    "        iB = sys_id.B #np.ones((nx,1))\n",
    "        #%%\n",
    "        # nbases=4\n",
    "        L = y.shape[1]//ratio_L\n",
    "        steps = samples_num\n",
    "       ```\n",
    "  - We create `Simulation` instance, and initialize its parameters\n",
    "       ```python\n",
    "        sim = a.Simulate(steps,nx,u_extend,y_extend,bases_num,L,PFweightNum=particles_num)\n",
    "        if useLinear:\n",
    "            sim.iA = iA\n",
    "            sim.iB = iB \n",
    "        ```\n",
    "        \n",
    "        ```python\n",
    "        sim.burnInPercentage = burnPercentage\n",
    "        sim.lQ = lQ #for prior QR\n",
    "        sim.ell = ell\n",
    "        sim.Vgain = Vgain\n",
    "        ```\n",
    "  - Lastly we run the simulation by `sim.run()`, do the evaluation using the test data by `sim.evaluate()` and save the result in `hdf5` file by `sim.save(...)`\n",
    "      ```python\n",
    "        sim.run()\n",
    "        #%%\n",
    "        y_test_med,y_test_loQ,y_test_hiQ = sim.evaluate(y_test,u_test,Kn=Kn)\n",
    "\n",
    "        sim.save(str(simResultPath/'result.hdf5'))\n",
    "      ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The particle filter and MCMC part is implemented in `a.py'\n",
    "- Some snippets:\n",
    "- Implementation of `run()`\n",
    "    ```python\n",
    "    def run(self):\n",
    "        \n",
    "        for k in trange(self.__steps,desc='Simulation'):\n",
    "            #This probabiy not required\n",
    "            self.setToZero()           \n",
    "            #Initialization\n",
    "            if k>0:\n",
    "                self.__xPF[-1,:,:] = self.__x_prim\n",
    "            \n",
    "            self.__PFweight[0,:] = 1.\n",
    "            self.__PFweight[0,:] /= np.sum(self.__PFweight[0,:])\n",
    "            \n",
    "            # CPF with ancestor sampling\n",
    "            self.__xPF[:-1,:,0] = 0\n",
    "    ```\n",
    "    ```python\n",
    "            self.__runParticleFilter(k)\n",
    "            star = util.systematic_resampling(self.__PFweight[-1,:],1)\n",
    "            self.__x_prim[:,-1] = self.__xPF[star,:,-1].flatten()\n",
    "\n",
    "            #loop from the back\n",
    "            for t in np.flip(np.arange(1,self.__timeStep)):\n",
    "                star = self.__a[t,star]\n",
    "                self.__x_prim[:,t-1] = self.__xPF[star,:,t-1].flatten()\n",
    "            # print('Sampling. k = {}/{}'.format(k,self.__steps))\n",
    "            self.__update_statistics()\n",
    "    ```\n",
    "- Both `__update_statistics()` and `__runParticleFilter(k)` implemented in `util.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
