{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonlinear Greybox System Identification \n",
    "\n",
    "In this notebook we attempt to do greybox type of nonlinear system identification. The starting point is the dynamic given by Thomas Price and John Butt in *Catalyst Poisoning and Fixed Bed Reactor Dynamic II: Adiabatic Reactors*. \n",
    "The starting assumptions are the following:\n",
    "1. The input to the dynamic is the inlet temperature, the aromatic flow rate, the sulfur flow rate.\n",
    "2. Diffusion dynamic on planar axis is neglected.\n",
    "3. Partial differentiation with respect to horizontal axis is approximated by its backward numerical differentiation,\n",
    "   i.e., \n",
    "   $$\\left. \\dfrac{\\partial T}{\\partial z}\\right|_{z=z_i} \\approx \\frac{1}{\\Delta z} \\left[T(z_i) - T(z_{i-1})\\right],\\\\\n",
    "     \\left.\\dfrac{\\partial^2 T}{\\partial^2 z}\\right|_{z=z_i} \\approx \\frac{1}{\\Delta z} \\left[\\left. \\dfrac{\\partial T}{\\partial z}\\right|_{z=z_i} - \\left. \\dfrac{\\partial T}{\\partial z}\\right|_{z=z_{i-1}}\\right],\\\\\n",
    "     \\approx \\frac{1}{(\\Delta z)^2}\\left[T(z_i) - 2T(z_{i-1}) + T(z_{i-2})\\right]\\\\\n",
    "   $$\n",
    "\n",
    "The pde of the catalyst dynamic is given by:\n",
    "$$\n",
    "\\dfrac{d s_i}{dt} = K_0 \\dfrac{\\partial^2 s_i}{\\partial^2 z} -K_1 \\dfrac{\\partial s_i}{\\partial z}  - K_2 r_s(s_i,T_i) c_i,\\\\\n",
    "\\dfrac{d a_i}{dt} = K_3 \\dfrac{\\partial^2 a_i}{\\partial^2 z} -K_1 \\dfrac{\\partial a_i}{\\partial z} - K_2 r_a(a_i,T_i,c_i) c_i,\\\\\n",
    "\\dfrac{d T_i}{dt} = K_4 \\dfrac{\\partial^2 T_i}{\\partial^2 z} -K_5 \\dfrac{\\partial T_i}{\\partial z} + K_6 r_a(a_i,T_i,c_i) c_i,\\\\\n",
    "\\dfrac{d c_i}{dt} = K_7 r_s(s_i,T_i) c_i,\n",
    "$$\n",
    "   \n",
    "\n",
    "\n",
    "Let the reactor is partitioned into $N$ layers, where for each, the temperature corresponds to that layer is measured. The state each layer is given by (all is normalized):\n",
    "1. $s_i$ Sulfur concentration.\n",
    "2. $a_i$ Aromatic concentration.\n",
    "3. $T_i$ Temperature.\n",
    "4. $c_i$ Catalyst activity.\n",
    "\n",
    "where here $i = 1, \\cdots, N$.\n",
    "\n",
    "The inputs to the reactor are given by\n",
    "1. $s_0$ Sulfur concentration at inlet.\n",
    "2. $a_0$ Aromatic concentration at inlet.\n",
    "3. $T_0$ Temperature inlet.\n",
    "\n",
    "For each $i = 1, \\cdots, N$ the dyanmics are expressed as follows:\n",
    "$$\n",
    "\\dfrac{d s_i}{dt} = K_0 \\dfrac{1}{(\\Delta z)^2} \\left[s_i(t) -2 s_{i-1}(t) + s_{i-2}(t)\\right] -K_1 \\dfrac{1}{\\Delta z} \\left[s_i(t) - s_{i-1}(t)\\right]  - K_2 r_s(s_i,T_i) c_i,\\\\\n",
    "\\dfrac{d a_i}{dt} = K_3 \\dfrac{1}{(\\Delta z)^2} \\left[a_i(t) -2 a_{i-1}(t) + a_{i-2}(t)\\right] -K_1 \\dfrac{1}{\\Delta z} \\left[a_i(t) - a_{i-1}(t)\\right] - K_2 r_a(a_i,T_i,c_i) c_i,\\\\\n",
    "\\dfrac{d T_i}{dt} = K_4 \\dfrac{1}{(\\Delta z)^2} \\left[T_i(t) -2 T_{i-1}(t) + T_{i-2}(t)\\right] -K_5 \\dfrac{1}{\\Delta z} \\left[T_i(t) - T_{i-1}(t)\\right] + K_6 r_a(a_i,T_i,c_i) c_i,\\\\\n",
    "\\dfrac{d c_i}{dt} = K_7 r_s(s_i,T_i) c_i,\n",
    "$$\n",
    "where \n",
    "$$\n",
    "r_a = -d_1 \\exp\\left(-d_2/T_i\\right) a_i c_i,\\\\\n",
    "r_s = -d_3 \\exp\\left(-d_4/T_i\\right)s_i %\\dfrac{d_3 \\exp\\left((d_4-d_5)/T_i\\right)s_i}{1+d_6 \\exp(d_4/T_i)s_i}.\n",
    "$$\n",
    "\n",
    "In these dynamical equations, the constants $K_j$ and $d_j$ belongs to $\\mathbb{R}^+$, to be estimated from the data via nonlinear optimization algorithm. We do not include noises model in the dynamics nor in the measurement model. We would handle this via stochastic smoothing or Gaussian processes system identification. These dynamics will be the starting point. It is assumed that initially $c_i = 1, \\forall i$.\n",
    "\n",
    "We then discretize the dynamics above in time, resulting in the following dynamics:\n",
    "$$\n",
    "s_i(t+1) = s_i(t)+K_0 \\dfrac{1}{(\\Delta z)^2} \\left[s_i(t) -2 s_{i-1}(t) + s_{i-2}(t)\\right] -K_1 \\dfrac{1}{\\Delta z} \\left[s_i(t) - s_{i-1}(t)\\right]  - K_2 r_s(s_i,T_i) c_i,\\\\\n",
    "a_i(t+1) = a_i(t)+K_3 \\dfrac{1}{(\\Delta z)^2} \\left[a_i(t) -2 a_{i-1}(t) + a_{i-2}(t)\\right] -K_1 \\dfrac{1}{\\Delta z} \\left[a_i(t) - a_{i-1}(t)\\right] - K_2 r_a(a_i,T_i,c_i) c_i,\\\\\n",
    "T_i(t+1) = T_i(t)+K_4 \\dfrac{1}{(\\Delta z)^2} \\left[T_i(t) -2 T_{i-1}(t) + T_{i-2}(t)\\right] -K_5 \\dfrac{1}{\\Delta z} \\left[T_i(t) - T_{i-1}(t)\\right] + K_6 r_a(a_i,T_i,c_i) c_i,\\\\\n",
    "c_i(t+1) = c_i(t)+ K_7 r_s(s_i,T_i) c_i,\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "We could start $u(t,z_i) = K_4 r_a(s_i(t),T_i(t)) c_i(t)$.\n",
    "\n",
    "$$\n",
    "c_i = c_i(0) \\exp(\\int r_s(t) dt)\\\\\n",
    "u_i = -r_a(a_i,T_i,c_i) c_i(0) \\exp(\\int r_s(t) dt)\\\\\n",
    "    = d_1 \\exp\\left(-d_2/T_i\\right) a_i c_i(0)^2 \\exp(2 \\int r_s(t) dt)\\\\\n",
    "    = d_1 \\exp\\left(-d_2/T_i\\right) \\exp(\\alpha_i(t,z_i)) c_i(0)^2 \\exp(2 \\int r_s(t,z_i) dt)\\\\\n",
    "\\log(u_i) = \\log(d_1) -d_2/T_i + \\alpha_i(t,z_i) + 2\\log(c_i(0)) + 2 \\int r_s(t,z_i) dt\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "Dtype = torch.float\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define discrete dynamics that will be used for system identification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Discrete catalyst dynamics, with assumption that the number of layer is 7\n",
    "The diffusion take into account here\n",
    "'''\n",
    "# @torch.jit.script\n",
    "def catalyst_dynamics(x,u,n_levels,Delta_z,K,d):\n",
    "    #input are the log\n",
    "    d = torch.exp(d)\n",
    "    K = torch.exp(K)\n",
    "#     d = torch.max(d,torch.zeros_like(d))\n",
    "#     d = torch.max(K,torch.zeros_like(K))\n",
    "    \n",
    "    s_in = u[0]\n",
    "    a_in = u[1]\n",
    "    T_in = u[2]\n",
    "\n",
    "    #get the current states\n",
    "    s = x[:n_levels]\n",
    "    a = x[n_levels:2*n_levels]\n",
    "    T = x[2*n_levels:3*n_levels]\n",
    "    c = x[3*n_levels:]\n",
    "    \n",
    "    #create new state\n",
    "    x_new = torch.zeros_like(x)\n",
    "    s_new = x_new[:n_levels] #This is only view\n",
    "    a_new = x_new[n_levels:2*n_levels]\n",
    "    T_new = x_new[2*n_levels:3*n_levels]\n",
    "    c_new = x_new[3*n_levels:]\n",
    "    \n",
    "    for i in range(n_levels):\n",
    "        if i == 0:\n",
    "            s_i_min_1 = s_in\n",
    "            a_i_min_1 = a_in\n",
    "            T_i_min_1 = T_in\n",
    "            \n",
    "            s_i_min_2 = s_in\n",
    "            a_i_min_2 = a_in\n",
    "            T_i_min_2 = T_in\n",
    "        else:\n",
    "            s_i_min_1 = s[i-1]\n",
    "            a_i_min_1 = a[i-1]\n",
    "            T_i_min_1 = T[i-1]\n",
    "            if i==1:\n",
    "                s_i_min_2 = s_in\n",
    "                a_i_min_2 = a_in\n",
    "                T_i_min_2 = T_in\n",
    "            else:\n",
    "                s_i_min_2 = s[i-2]\n",
    "                a_i_min_2 = a[i-2]\n",
    "                T_i_min_2 = T[i-2]\n",
    "        \n",
    "        Delta_s = (s[i] - s_i_min_1)/Delta_z[i]\n",
    "        Delta_a = (a[i] - a_i_min_1)/Delta_z[i]\n",
    "        Delta_T = (T[i] - T_i_min_1)/Delta_z[i]\n",
    "        \n",
    "        \n",
    "        Delta2_s = (s[i] - 2*s_i_min_1 + s_i_min_2)/(Delta_z[i]*Delta_z[i])\n",
    "        Delta2_a = (a[i] - 2*a_i_min_1 + a_i_min_2)/(Delta_z[i]*Delta_z[i])\n",
    "        Delta2_T = (T[i] - 2*T_i_min_1 + T_i_min_2)/(Delta_z[i]*Delta_z[i])\n",
    "        \n",
    "        \n",
    "        rA_i = rA(s[i],T[i],d)\n",
    "        rS_i = rS(a[i],T[i],c[i],d)\n",
    "        \n",
    "        s_new[i] = s[i]+K[0]*Delta2_s - K[1]*Delta_s - K[2]*rS_i*c[i]\n",
    "        a_new[i] = a[i]+K[3]*Delta2_a - K[1]*Delta_a - K[2]*rA_i*c[i]\n",
    "        T_new[i] = T[i]+K[4]*Delta2_T - K[5]*Delta_T + K[6]*rA_i*c[i]\n",
    "        c_new[i] = c[i]+K[7]*rS_i\n",
    "        \n",
    "        \n",
    "    return x_new\n",
    "\n",
    "# @torch.jit.script\n",
    "def temperature_output(x,n_levels=7):\n",
    "    return x[2*n_levels:3*n_levels]\n",
    "\n",
    "'''\n",
    "Aromatic reaction rate\n",
    "'''\n",
    "# @torch.jit.script\n",
    "def rA(s,T,d):\n",
    "\n",
    "    res =  -d[2]*torch.exp(-d[3]/T)*s;\n",
    "#     res = res/(1+(d[4]*exp(d[3]/T)*s));\n",
    "    return res\n",
    "\n",
    "'''\n",
    "Sulphur reaction rate\n",
    "'''\n",
    "# @torch.jit.script\n",
    "def rS(a,T,c,d):\n",
    "    res =  -d[0]*torch.exp(-d[1]/T)*a*c;\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Discrete catalyst dynamics, where the dispersion is not assumed\n",
    "'''\n",
    "# @torch.jit.script\n",
    "def simple_catalyst_dynamics(x,u,n_levels,Delta_z,K,d):\n",
    "\n",
    "    #input are the log\n",
    "    d = torch.exp(d)\n",
    "    K = torch.exp(K)\n",
    "#     d = torch.max(d,torch.zeros_like(d))\n",
    "#     d = torch.max(K,torch.zeros_like(K))\n",
    "    \n",
    "    s_in = u[0]\n",
    "    a_in = u[1]\n",
    "    T_in = u[2]\n",
    "\n",
    "    #get the current states\n",
    "    s = x[:n_levels]\n",
    "    a = x[n_levels:2*n_levels]\n",
    "    T = x[2*n_levels:3*n_levels]\n",
    "    c = x[3*n_levels:]\n",
    "    \n",
    "    #create new state\n",
    "    x_new = torch.zeros_like(x)\n",
    "    s_new = x_new[:n_levels] #This is only view\n",
    "    a_new = x_new[n_levels:2*n_levels]\n",
    "    T_new = x_new[2*n_levels:3*n_levels]\n",
    "    c_new = x_new[3*n_levels:]\n",
    "    \n",
    "    for i in range(n_levels):\n",
    "        if i == 0:\n",
    "            s_i_min_1 = s_in\n",
    "            a_i_min_1 = a_in\n",
    "            T_i_min_1 = T_in\n",
    "            \n",
    "        else:\n",
    "            s_i_min_1 = s[i-1]\n",
    "            a_i_min_1 = a[i-1]\n",
    "            T_i_min_1 = T[i-1]\n",
    "            \n",
    "        \n",
    "        Delta_s = (s[i] - s_i_min_1)/Delta_z[i]\n",
    "        Delta_a = (a[i] - a_i_min_1)/Delta_z[i]\n",
    "        Delta_T = (T[i] - T_i_min_1)/Delta_z[i]\n",
    "        \n",
    "        \n",
    "        rA_i = rA(s[i],T[i],d)\n",
    "        \n",
    "        rS_i = rS(a[i],T[i],c[i],d)\n",
    "        \n",
    "        s_new[i] = s[i]- K[0]*Delta_s - K[1]*rS_i*c[i]\n",
    "        a_new[i] = a[i]- K[0]*Delta_a - K[1]*rA_i*c[i]\n",
    "        T_new[i] = T[i]- K[2]*Delta_T + K[3]*rA_i*c[i]\n",
    "        c_new[i] = c[i]+K[4]*rS_i\n",
    "        \n",
    "        \n",
    "    return x_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define costumized `Torch.nn` so that the parameter could be handled with `Torch.optim` algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use Torch nn structure for easy manipulation of gradient and update\n",
    "class GreyIdentification(nn.Module):\n",
    "    def __init__(self,device,n_levels,initial_state,K_init,d_init,input_scale_init,simple=False):\n",
    "        super(GreyIdentification,self).__init__()\n",
    "        self.n_levels = n_levels\n",
    "        self.Delta_z = torch.tensor([1.,1.,1.,1.,1.,1.,1.],dtype=Dtype,device=device)\n",
    "        self.input_scale = nn.Parameter(data=input_scale_init,requires_grad=True)\n",
    "        self.K = nn.Parameter(data=K_init,requires_grad=True)\n",
    "        self.d = nn.Parameter(data=d_init,requires_grad=True)\n",
    "        self.initial_state = initial_state ##this can be estimated as well in the future\n",
    "#         self.state = initial_state.clone()#state at current time\n",
    "        self.useSimple = simple\n",
    "        if self.useSimple:\n",
    "            self.dynamics = simple_catalyst_dynamics\n",
    "        else:\n",
    "            self.dynamics = catalyst_dynamics\n",
    "        \n",
    "    \n",
    "    '''\n",
    "    forward, given a history of input u, the network will predict the history of output y\n",
    "    '''\n",
    "    def forward(self,u_hist):\n",
    "        #first we need to sclae the input\n",
    "        u_hist = torch.cat((torch.exp(self.input_scale),torch.tensor([1.],device=device)))*u_hist\n",
    "        state = self.initial_state.clone()\n",
    "        output_hist = torch.empty(u_hist.shape[0],self.n_levels,dtype=Dtype,device=device)\n",
    "        output_hist[0,:] = temperature_output(state,self.n_levels)\n",
    "        \n",
    "        \n",
    "        for i in range(u_hist.shape[0]-1):\n",
    "            state = self.dynamics(state,u_hist[i,:],self.n_levels,self.Delta_z,self.K,self.d)\n",
    "            output_hist[i+1,:] = temperature_output(state,self.n_levels)\n",
    "            \n",
    "        return output_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Kate & Alex\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, n_levels=7, window=28, add_noise=False):\n",
    "        self.a_in = torch.from_numpy(df['AROM-LC wt-%'].values).float()\n",
    "        self.s_in = torch.from_numpy(df['sulphur feed max'].values).float()\n",
    "        self.temp_in = torch.from_numpy(df['TI8585'].values).float()\n",
    "        self.temp = torch.from_numpy(df[temperature_columns[0,1:-1]].values).float()\n",
    "               \n",
    "        self.dates = df.index\n",
    "        self.window = window\n",
    "        self.add_noise = add_noise\n",
    "    \n",
    "    def __len__(self):\n",
    "        times = self.a_in.shape[0]\n",
    "        return times - self.window + 1        \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        noise_s = 0.00001 * torch.randn(self.window) if self.add_noise else 0.0\n",
    "        noise_a = 0.01 * torch.randn(self.window) if self.add_noise else 0.0\n",
    "        noise_temp = 0.01 * torch.randn(self.window) if self.add_noise else 0.0\n",
    "        return (self.s_in[idx:idx+self.window] + noise_s, \\\n",
    "               self.a_in[idx:idx+self.window] + noise_a, \\\n",
    "               self.temp_in[idx:idx+self.window] + noise_temp, \\\n",
    "               self.temp[idx:idx+self.window].squeeze(), \\\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_hdf('../Data/timeseries_complete.hdf5',key='KAAPO_hour_15_16_17_18_19_complete')\n",
    "df_raw = df_raw[(df_raw.index < \"2017-03-26\") & (df_raw.index > \"2015-07-14\")]\n",
    "df_lab = pd.read_hdf('../Data/Laboratory.hdf5',key='Laboratory').interpolate()\n",
    "df_lab = df_lab[(df_lab.index < \"2017-03-26\") & (df_lab.index > \"2015-07-14\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_columns = np.array(\n",
    "    [['TI8585','TI8553','TI8554','TI8555','TI8556','TI8557','TI8558','TI8559', 'TIZ8578A'],\n",
    "     ['TI8585','TI8560','TI8561','TI8562','TI8563','TI8564','TI8565','TI8566', 'TIZ8578A'],\n",
    "     ['TI8585','TI8567','TI8568','TI8569','TI8570','TI8571','TI8572','TI8573', 'TIZ8578A']],dtype=object)\n",
    "tc_heights =np.array([[7600,6550,5500,4450,3400,2350,1300],\n",
    "             [7250,6250,5150,4100,3050,2000,950],\n",
    "             [6900,5850,4800,3750,2700,1650,600]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select interval of interest and resample dataframe to daily data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_raw, df_lab], axis=1)\n",
    "df = df.resample('W').median() #resample daily or weekly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = CustomDataset(df, n_levels=7, window=28, add_noise=False)\n",
    "trainloader = DataLoader(dataset=trainset, batch_size=1, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 7])"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "# u_hist = torch.tensor(df[['AI8510A','Aromatic_percentage','TI8585']].values,device=device).float()\n",
    "u_hist = torch.tensor(df[['sulphur feed max','AROM-LC wt-%','TI8585']].fillna(0).values,device=device).float()\n",
    "y_hist = torch.tensor(df[temperature_columns[0,1:-1]].values,device=device).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of layer\n",
    "layer_num = 7\n",
    "\n",
    "#set initial state\n",
    "s_init = u_hist[0,0]*torch.ones(layer_num,device=device,dtype=Dtype)\n",
    "a_init = u_hist[0,1]*torch.ones(layer_num,device=device,dtype=Dtype)\n",
    "T_init = y_hist[0,:]\n",
    "c_init = torch.ones(layer_num,device=device)\n",
    "initial_state = torch.cat((s_init,a_init,T_init,c_init))\n",
    "\n",
    "#initialize the parameter\n",
    "K_init = torch.log(torch.tensor([0.1090, 0.9871, 0.7476, 0.1604, 0.3059, 0.5792, 0.6542, 0.4632],dtype=Dtype,device=device))\n",
    "# K_init = torch.tensor([0.1090, 0.9871, 0.7476, 0.1604, 0.3059, 0.5792, 0.6542, 0.4632],dtype=Dtype,device=device)\n",
    "# K_init = torch.randn(8,dtype=Dtype,device=device)\n",
    "\n",
    "K_init_simple = torch.log(torch.tensor([0.9871, 0.7476, 0.5792, 0.6542, 0.4632],dtype=Dtype,device=device))\n",
    "# K_init_simple = torch.tensor([0.9871, 0.7476, 0.5792, 0.6542, 0.4632],dtype=Dtype,device=device)\n",
    "# K_init = torch.exp(torch.randn(8))\n",
    "\n",
    "d_init = torch.log(torch.tensor([0.2073, 0.1953, 0.8495, 0.8825],dtype=Dtype,device=device))\n",
    "# d_init = torch.tensor([0.2073, 0.1953, 0.8495, 0.8825],dtype=Dtype,device=device)\n",
    "# d_init = torch.tensor([0.2073, 0.1953, 0.8495, 0.8825],dtype=Dtype)\n",
    "\n",
    "input_scale_init = torch.randn(2,device=device)\n",
    "\n",
    "greyIdentification = GreyIdentification(device,7,initial_state,K_init_simple,d_init,input_scale_init,simple=True)\n",
    "# greyIdentification = GreyIdentification(device,7,initial_state,K_init,d_init,input_scale_init)\n",
    "greyIdentification.input_scale.data = torch.tensor([0.4789, 1.4224],dtype=Dtype,device=device)\n",
    "#Define loss function\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "#use Adam at the moment for the optimizer\n",
    "# optimizer = torch.optim.Adam(greyIdentification.parameters(), lr=learning_rate)\n",
    "\n",
    "#use Adadelta\n",
    "optimizer = torch.optim.AdamW(greyIdentification.parameters(), lr=learning_rate)\n",
    "train_len = len(trainloader)\n",
    "epochs = 100\n",
    "# use scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=train_len, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check whether the dynamics with initial K_init and d_init can be runned through all timesteps without giving `nan` or `inf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False, device='cuda:0')"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_hist = torch.empty(u_hist.shape[0],28,device=device)\n",
    "state = initial_state.clone()\n",
    "state_hist[0,:] = state\n",
    "for i in range(u_hist.shape[0]-1):\n",
    "    state = greyIdentification.dynamics(state,u_hist[i,:],greyIdentification.n_levels,\\\n",
    "                                        greyIdentification.Delta_z,K_init,d_init)\n",
    "    state_hist[i+1,:] = state\n",
    "#     print(state[:layerNum])\n",
    "#     print(state[layerNum:2*layerNum])\n",
    "#     print(state[2*layer_num:3*layer_num])\n",
    "#     print(state[3*layer_num:])\n",
    "torch.any(torch.isnan(state_hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2ab495579310>,\n",
       " <matplotlib.lines.Line2D at 0x2ab4955795d0>,\n",
       " <matplotlib.lines.Line2D at 0x2ab495579790>,\n",
       " <matplotlib.lines.Line2D at 0x2ab495579950>,\n",
       " <matplotlib.lines.Line2D at 0x2ab495579b10>,\n",
       " <matplotlib.lines.Line2D at 0x2ab495579cd0>,\n",
       " <matplotlib.lines.Line2D at 0x2ab495579f10>]"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(state_hist.to('cpu')[:,3*layer_num:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn the parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss is 6356032.604838709.\n",
      "Epoch 2: loss is 6156171.2822580645.\n",
      "Epoch 3: loss is nan.\n",
      "Epoch 4: loss is nan.\n",
      "Epoch 5: loss is nan.\n",
      "Epoch 6: loss is nan.\n",
      "Epoch 7: loss is nan.\n",
      "Epoch 8: loss is nan.\n",
      "Epoch 9: loss is nan.\n",
      "Epoch 10: loss is nan.\n",
      "Epoch 11: loss is nan.\n",
      "Epoch 12: loss is nan.\n",
      "Epoch 13: loss is nan.\n",
      "Epoch 14: loss is nan.\n",
      "Epoch 15: loss is nan.\n",
      "Epoch 16: loss is nan.\n",
      "Epoch 17: loss is nan.\n",
      "Epoch 18: loss is nan.\n",
      "Epoch 19: loss is nan.\n",
      "Epoch 20: loss is nan.\n",
      "Epoch 21: loss is nan.\n",
      "Epoch 22: loss is nan.\n",
      "Epoch 23: loss is nan.\n",
      "Epoch 24: loss is nan.\n",
      "Epoch 25: loss is nan.\n",
      "Epoch 26: loss is nan.\n",
      "Epoch 27: loss is nan.\n",
      "Epoch 28: loss is nan.\n",
      "Epoch 29: loss is nan.\n",
      "Epoch 30: loss is nan.\n",
      "Epoch 31: loss is nan.\n",
      "Epoch 32: loss is nan.\n",
      "Epoch 33: loss is nan.\n",
      "Epoch 34: loss is nan.\n",
      "Epoch 35: loss is nan.\n",
      "Epoch 36: loss is nan.\n",
      "Epoch 37: loss is nan.\n",
      "Epoch 38: loss is nan.\n"
     ]
    }
   ],
   "source": [
    "#Set how many epoch?\n",
    "for ep in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for s_in, a_in, t_in, y in trainloader:\n",
    "        \n",
    "        a_in = a_in.to(device)\n",
    "        s_in = s_in.to(device)\n",
    "        t_in = s_in.to(device)\n",
    "        y = y.to(device).squeeze()\n",
    "        \n",
    "\n",
    "        # shape feed_in = (batch_size, n_times, 2)\n",
    "        u = torch.stack([s_in,s_in,t_in], dim=2).squeeze()\n",
    "        y_pred = greyIdentification(u)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(y_pred,y)\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    scheduler.step(epoch_loss)\n",
    "    print(\"Epoch {0}: loss is {1}.\".format(ep + 1, epoch_loss / train_len))\n",
    "    \n",
    "    \n",
    "#     y_hist_pred = greyIdentification(u_hist)\n",
    "#     loss = loss_fn(y_hist,y_hist_pred)\n",
    "#     if ep % 10 == 9:\n",
    "#         print(ep, loss.item())\n",
    "\n",
    "    \n",
    "#     optimizer.zero_grad()\n",
    "\n",
    "#     # Backward pass: compute gradient of the loss with respect to model\n",
    "#     # parameters\n",
    "#     loss.backward(retain_graph=True)#but why\n",
    "\n",
    "#     # Calling the step function on an Optimizer makes an update to its\n",
    "#     # parameters\n",
    "#     optimizer.step()\n",
    "    \n",
    "#     #call scheduler\n",
    "#     scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[204.7490, 204.8300, 199.4270, 207.7520, 207.4340, 206.9350, 207.6830],\n",
       "        [148.8460, 141.8653, 200.3581, 206.6313, 204.4567, 206.6551, 207.1196],\n",
       "        [107.8112,  97.9093, 186.0825, 186.4904, 202.6127, 206.2107, 205.8066],\n",
       "        [ 78.0251,  67.0676, 164.5510, 158.8272, 197.5732, 199.7610, 204.2824],\n",
       "        [ 56.8284,  45.7944, 140.5987, 129.8921, 188.2384, 186.7476, 201.8366],\n",
       "        [ 41.5480,  31.4837, 117.5622, 103.0138, 175.0516, 168.7362, 197.6640],\n",
       "        [ 30.4140,  21.6463,  97.0255,  80.1115, 159.3231, 147.8548, 191.2637],\n",
       "        [ 22.3615,  14.9393,  79.1528,  61.4752, 142.6531, 126.2718, 182.5754],\n",
       "        [ 16.5666,  10.4269,  63.9473,  46.5701, 125.9227, 105.6634, 172.0137],\n",
       "        [ 12.3507,   7.3486,  51.2703,  34.8839, 109.6565,  86.8147, 160.0793],\n",
       "        [  9.2585,   5.2248,  40.8581,  25.8764,  94.3444,  70.1040, 147.1382],\n",
       "        [  6.9285,   3.6957,  32.4040,  19.0288,  80.3194,  55.7121, 133.6183],\n",
       "        [  5.2828,   2.7197,  25.5883,  13.8671,  67.7544,  43.6208, 119.9774],\n",
       "        [  4.0847,   2.0667,  20.1558,  10.0457,  56.6956,  33.6697, 106.6136],\n",
       "        [  3.2128,   1.6328,  15.8561,   7.2512,  47.1110,  25.6353,  93.8384],\n",
       "        [  2.6652,   1.4453,  12.4732,   5.2322,  38.9113,  19.2601,  81.8772],\n",
       "        [  2.2665,   1.3278,   9.8488,   3.8215,  31.9741,  14.2828,  70.8756],\n",
       "        [  1.9763,   1.2560,   7.8198,   2.8491,  26.1674,  10.4661,  60.9113],\n",
       "        [  1.7652,   1.2139,   6.2560,   2.1892,  21.3512,   7.5897,  52.0085],\n",
       "        [  1.4701,   1.0312,   5.0541,   1.7498,  17.3880,   5.4595,  44.1496],\n",
       "        [  1.2553,   0.9084,   4.0949,   1.4154,  14.1491,   3.9106,  37.2865],\n",
       "        [  1.2158,   0.9582,   3.3349,   1.1675,  11.5084,   2.7923,  31.3502],\n",
       "        [  1.1870,   0.9958,   2.7677,   1.0284,   9.3613,   1.9933,  26.2573],\n",
       "        [  1.1633,   1.0211,   2.3446,   0.9583,   7.6289,   1.4431,  21.9186],\n",
       "        [  1.1461,   1.0403,   2.0284,   0.9297,   6.2402,   1.0808,  18.2476],\n",
       "        [  1.2151,   1.1469,   1.7922,   0.9256,   5.1332,   0.8563,  15.1616],\n",
       "        [  1.2654,   1.2221,   1.6377,   0.9635,   4.2549,   0.7297,  12.5831],\n",
       "        [  1.3020,   1.2751,   1.5380,   1.0194,   3.5667,   0.6796,  10.4408]],\n",
       "       device='cuda:0', grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greyIdentification.input_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-2.1636,  0.0270, -0.3220, -1.8716, -1.2107, -0.5198, -0.4577, -0.7313],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greyIdentification.K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-1.5408, -1.6528, -0.1959, -0.0939], device='cuda:0',\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greyIdentification.d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filename):\n",
    "    try:\n",
    "        do_save = input('Do you want to save the model (type yes to confirm)? ').lower()\n",
    "        if do_save == 'yes':\n",
    "            torch.save(model.state_dict(), filename)\n",
    "            print('Model saved to %s.' % (filename))\n",
    "        else:\n",
    "            print('Model not saved.')\n",
    "    except:\n",
    "        raise Exception('The notebook should be run or validated with skip_training=True.')\n",
    "\n",
    "\n",
    "def load_model(model, filename, device):\n",
    "    model.load_state_dict(torch.load(filename, map_location=lambda storage, loc: storage))\n",
    "    print('Model loaded from %s.' % filename)\n",
    "    model.to(device)\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to save the model (type yes to confirm)?  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model not saved.\n"
     ]
    }
   ],
   "source": [
    "skip_training=T\n",
    "if not skip_training:\n",
    "    save_model(greyIdentification, 'greyIdentification.pth')\n",
    "    \n",
    "else:\n",
    "    n_levels = len(selected_cols)\n",
    "    model = CustomRnn(n_levels, use_true_params=False)\n",
    "    load_model(greyIdentification, 'greyIdentification.pth', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0.])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(torch.tensor([1.,-1,0.]),torch.zeros(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
